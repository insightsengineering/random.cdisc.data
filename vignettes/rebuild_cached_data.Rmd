---
title: "Rebuilding Cached Random CDISC Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Rebuilding Cached Random CDISC Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}{inputenc}
---

## Getting Started

The following script is used to create, compare and save cached data to the `data/` directory.

Starting in `R 3.6.0` the default kind of under-the-hood random-number generator was changed.
Now, in order to get the results from `set.seed()` to match, you have to first call the
function `RNGkind(sample.kind = "Rounding")`.

It throws the expected warning:

```
Warning: non-uniform 'Rounding' sampler used
```

## Code Maintenance

Currently, when a `random.cdisc.data` data-generating function is created or modified, then the below code chunk must
be run to build the new/updated cached dataset and add it to the `data/` directory. If a dataset that is a dependency
for another dataset has been updated then the dependent dataset will also be updated. To manually specify which 
datasets should be updated, edit the `data_to_update` vector below, entering the desired dataset names.

## Update Cached Data

**Note:** Prior to running the following code chunk, please ensure that you have reinstalled the `random.cdisc.data` 
package after completing all dataset modifications.
```{r, eval=FALSE}
library(random.cdisc.data)
library(diffdf)
library(dplyr)

# Call function to match random number generation from previous R versions
RNGkind(sample.kind = "Rounding")

# Datasets must be listed after all of their dependencies
# e.g. adsl is a dependency for all other datasets so it is listed first.
pkg_dir <- dirname(getwd())

# Listing source files and extraction of datasets' names
src_files <- list.files(paste0(pkg_dir, "/R"))
data_nms <- src_files[grepl("^ra*", src_files)] %>%
  stringr::str_remove(pattern = "^r") %>%
  stringr::str_remove(pattern = ".R$") %>%
  sort()

# Exception handling
data_nms <- data_nms[data_nms != "adsaftte"] # Unbuilt for now

# Construction of dependency tree based on formals
data_deps <- sapply(
  data_nms,
  function(x) {
    dat_args <- names(formals(paste0("r", x)))
    dat_args[dat_args %in% data_nms]
  }
)

updated_files <- system("git diff origin/main --name-only", intern = TRUE)
updated_data <- updated_files[grepl("^R\\/", updated_files)] %>%
  stringr::str_remove("^R\\/") %>%
  stringr::str_remove(pattern = "^r") %>%
  stringr::str_remove(pattern = ".R$")

if (length(updated_data) != 0) {
  # Extracting relative dependencies
  update_after_deps <- unlist(
    sapply(seq_along(data_deps), function(x) {
      if (updated_data %in% data_deps[[x]]) {
        names(data_deps)[x]
      }
    })
  )
  data_to_update <- unique(c(updated_data, update_after_deps))
  data_to_update <- data_to_update[order(match(data_to_update, data_nms))] # order dependencies first

  # Generate and save updated cached datasets
  default_args <- list(seed = 1, na_vars = list(), who_coding = TRUE, percent = 80, number = 2)
  for (dat in data_to_update) {
    # Match arguments with defaults
    dat_args <- default_args[names(default_args) %in% names(formals(paste0("r", dat)))]

    # Get the data deps cache that is already there (if adsl returns list())
    dat_deps <- lapply(data_deps[[dat]], function(x) get(paste0("c", x)))

    # Main call to creation function
    cdataset <- do.call(paste0("r", dat), c(dat_args, dat_deps))
    attr(cdataset, "creation date") <- lubridate::date() # nolint

    # Preview differences (optional)
    cat("\nSaving cache for dataset", dat, "with the following changes (diffdf):\n")
    print(diffdf(get(paste0("c", dat)), cdataset))

    # Save new cached dataset
    assign(paste0("c", dat), cdataset)
    fl_save <- paste0(pkg_dir, "/data/c", dat, ".RData")
    save(list = paste0("c", dat), file = fl_save, compress = "xz")
    cat("Dataset cache updated for", dat, "in file", basename(fl_save), "\n")
  }
} else {
  message("No source file changed, hence no data cache is to be updated at the moment.")
}
```
