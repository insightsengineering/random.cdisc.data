---
title: "Rebuilding Cached Random CDISC Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Rebuilding Cached Random CDISC Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}{inputenc}
---

## Getting Started

The following script is used to create, compare and save cached data to the `data/` directory.

Starting in `R 3.6.0` the default kind of under-the-hood random-number generator was changed.
Now, in order to get the results from `set.seed()` to match, you have to first call the
function `RNGkind(sample.kind = "Rounding")`.

It throws the expected warning:

```
Warning: non-uniform 'Rounding' sampler used
```

## Code Maintenance

Currently, when a `random.cdisc.data` data-generating function is created or modified, then the below code chunk must
be run to build the new/updated cached dataset and add it to the `data/` directory. If a dataset that is a dependency
for another dataset has been updated then the dependent dataset will also be updated. To manually specify which 
datasets should be updated, edit the `data_to_update` vector below, entering the desired dataset names.

## Update Cached Data

**Note:** Prior to running the following code chunk, please ensure that you have reinstalled the `random.cdisc.data` 
package after completing all dataset modifications.
```{r, eval=FALSE}
library(random.cdisc.data)
library(diffdf)
library(dplyr)

# Call function to match random number generation from previous R versions
RNGkind(sample.kind = "Rounding")

# Datasets must be listed after all of their dependencies
# e.g. adsl is a dependency for all other datasets so it is listed first.

# Listing source files and extraction of datasets' names
src_files <- list.files(paste0(dirname(getwd()), "/R"))
data_nms <- src_files[grepl("^ra*", src_files)] %>% 
  stringr::str_remove(pattern = "^r") %>% 
  stringr::str_remove(pattern = ".R$") %>% 
  sort() 

# Exception handling
data_nms <- data_nms[data_nms != "adsaftte"] # Unbuilt for now

# Construction of dependency tree based on formals
data_deps <- sapply(
  data_nms,
  function(x) {
    dat_args <- names(formals(paste0("r", x)))
    dat_args[dat_args %in% data_nms]
  }
)

updated_files <- system("git diff main --name-only", intern = TRUE)
updated_data <- gsub("R/r|.R", "", grep("R/r", updated_files, value = TRUE))

if (length(updated_data) != 0) {
  update_after_deps <- unlist(
    sapply(updated_data, function(x) data_nms[sapply(data_deps, function(deps) x %in% deps)])
  )
  data_to_update <- unique(c(updated_data, update_after_deps))
  data_to_update <- data_to_update[order(match(data_to_update, data_nms))] # order dependencies first
  
  # Generate and save updated cached datasets
  default_args <- list(seed = 1, na_vars = list(), who_coding = TRUE, percent = 80, number = 2)
  for (dat in data_to_update) {
    dat_args <- default_args[names(default_args) %in% names(formals(paste0("r", dat)))]
    dat_deps <- lapply(data_deps[[dat]], function(x) get(paste0("c", x)))
    cdataset <- do.call(paste0("r", dat), c(dat_args, dat_deps))
    attr(cdataset, "creation date") <- Sys.Date() # nolint
  
    # Preview differences (optional)
    print(paste("Dataset:", dat))
    print(diffdf(get(paste0("c", dat)), cdataset))
  
    # Save new cached dataset
    assign(paste0("c", dat), cdataset)
    save(list = paste0("c", dat), file = paste0("../data/c", dat, ".RData"), compress = "xz")
  }
} else {
  message("No source file changed, hence no data cache is to be updated at the moment.")
}
```
